{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd65045-9aef-4083-b60c-bd090a97c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982b09b1-c5e0-40a9-8814-f23b8bc51603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/miniconda3/envs/dl/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-1.3b-base\", trust_remote_code=True, cache_dir=\"/home/maxim/models\")\n",
    "# model_2 = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"deepseek-ai/deepseek-coder-1.3b-base\", \n",
    "#     trust_remote_code=True, \n",
    "#     cache_dir=\"/home/maxim/models\",\n",
    "#     attn_implementation=\"eager\",\n",
    "#     # torch_dtype=torch.float16,\n",
    "# ).cuda()\n",
    "# model_2 = model_2.half()\n",
    "# print(model)\n",
    "# print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3bbd04f-8229-4a00-b084-298a9ef6b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bigcode/tiny_starcoder_py\"\n",
    "device = \"cuda\" # for GPU usage or \"cpu\" for CPU usage\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=\"/home/maxim/models\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=\"/home/maxim/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ad513d-0d80-4393-9bb7-e620c5942054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBigCodeConfig {\n",
       "  \"_name_or_path\": \"bigcode/tiny_starcoder_py\",\n",
       "  \"activation_function\": \"gelu_pytorch_tanh\",\n",
       "  \"architectures\": [\n",
       "    \"GPTBigCodeForCausalLM\"\n",
       "  ],\n",
       "  \"attention_softmax_in_fp32\": true,\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"inference_runner\": 0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_batch_size\": null,\n",
       "  \"max_sequence_length\": null,\n",
       "  \"model_type\": \"gpt_bigcode\",\n",
       "  \"multi_query\": true,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": 3072,\n",
       "  \"n_layer\": 20,\n",
       "  \"n_positions\": 8192,\n",
       "  \"pad_key_length\": true,\n",
       "  \"pre_allocate_kv_cache\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attention_softmax_in_fp32\": true,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.41.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"validate_runner_input\": true,\n",
       "  \"vocab_size\": 49152\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ae50b5-3a3a-47d1-a85a-6267b878655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator.models.Bitnet.modeling_bitnet import BitnetForCausalLM\n",
    "from generator.models.Bitnet.configuration_bitnet import BitnetAttentionConfig, BitnetConfig, BitnetFFNConfig\n",
    "from generator.models.Llama.modeling_llama import LlamaForCausalLM\n",
    "from generator.models.GPTBigcode.modeling_gpt_bigcode import GPTBigCodeForCausalLM\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b938e9b2-1e78-41a4-b495-794b7cc21583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/miniconda3/envs/dl/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model_parent_config = AutoConfig.from_pretrained(\n",
    "#     \"deepseek-ai/deepseek-coder-1.3b-base\", \n",
    "#     trust_remote_code=True, \n",
    "#     cache_dir=\"/home/maxim/models\",\n",
    "#     attn_implementation=\"eager\",\n",
    "# )\n",
    "\n",
    "model_parent_config = AutoConfig.from_pretrained(\n",
    "    \"bigcode/tiny_starcoder_py\", \n",
    "    trust_remote_code=True, \n",
    "    cache_dir=\"/home/maxim/models\",\n",
    "    attn_implementation=\"eager\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0680b3-35bd-4a13-8bab-80c3ffcf73e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBigCodeConfig {\n",
       "  \"_name_or_path\": \"bigcode/tiny_starcoder_py\",\n",
       "  \"activation_function\": \"gelu_pytorch_tanh\",\n",
       "  \"architectures\": [\n",
       "    \"GPTBigCodeForCausalLM\"\n",
       "  ],\n",
       "  \"attention_softmax_in_fp32\": true,\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"inference_runner\": 0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_batch_size\": null,\n",
       "  \"max_sequence_length\": null,\n",
       "  \"model_type\": \"gpt_bigcode\",\n",
       "  \"multi_query\": true,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": 3072,\n",
       "  \"n_layer\": 20,\n",
       "  \"n_positions\": 8192,\n",
       "  \"pad_key_length\": true,\n",
       "  \"pre_allocate_kv_cache\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attention_softmax_in_fp32\": true,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.41.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"validate_runner_input\": true,\n",
       "  \"vocab_size\": 49152\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_parent_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca85a2a5-c2b0-45a7-90ce-02331df5a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/maxim/models/models--deepseek-ai--deepseek-coder-1.3b-base/snapshots/c919139c3a9b4070729c8b2cca4847ab29ca8d94'\n",
    "model_path = '/home/maxim/models/models--bigcode--tiny_starcoder_py/snapshots/8547527bef0bc927268c1653cce6948c5c242dd1'\n",
    "# parent_model = LlamaForCausalLM.from_pretrained(\n",
    "#     config=model_parent_config,\n",
    "#     pretrained_model_name_or_path=model_path,\n",
    "# ).cuda()\n",
    "\n",
    "parent_model = GPTBigCodeForCausalLM.from_pretrained(\n",
    "    config=model_parent_config,\n",
    "    pretrained_model_name_or_path=model_path,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "114a848e-f378-4153-8a06-c132f4474525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBigCodeConfig {\n",
       "  \"_name_or_path\": \"/home/maxim/models/models--bigcode--tiny_starcoder_py/snapshots/8547527bef0bc927268c1653cce6948c5c242dd1\",\n",
       "  \"activation_function\": \"gelu_pytorch_tanh\",\n",
       "  \"architectures\": [\n",
       "    \"GPTBigCodeForCausalLM\"\n",
       "  ],\n",
       "  \"attention_softmax_in_fp32\": true,\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"inference_runner\": 0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"max_batch_size\": null,\n",
       "  \"max_sequence_length\": null,\n",
       "  \"model_type\": \"gpt_bigcode\",\n",
       "  \"multi_query\": true,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": 3072,\n",
       "  \"n_layer\": 20,\n",
       "  \"n_positions\": 8192,\n",
       "  \"pad_key_length\": true,\n",
       "  \"pre_allocate_kv_cache\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attention_softmax_in_fp32\": true,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.41.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"validate_runner_input\": true,\n",
       "  \"vocab_size\": 49152\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "581fe0bf-3aa9-42b4-8c27-eb2d998ff924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0351ecbc-3933-4871-b7c7-1a595f10e553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "440935ca-c173-4551-8fd9-baac772747eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_config = BitnetAttentionConfig(\n",
    "    kv_n_heads=12,\n",
    ")\n",
    "\n",
    "ffn_config = BitnetFFNConfig(\n",
    "    ffn_hidden_size=768,\n",
    ")\n",
    "\n",
    "model_config = BitnetConfig(\n",
    "    attn_implementation=\"eager\",\n",
    "    d_model=384,\n",
    "    n_heads=12,\n",
    "    n_layers=20,\n",
    "    max_seq_len=256,\n",
    "    use_last_bit_linear=False,\n",
    "    vocab_size=len(tokenizer),\n",
    "    attn_config=attention_config,\n",
    "    ffn_config=ffn_config,\n",
    ")\n",
    "\n",
    "model = BitnetForCausalLM(model_config).to(\"cuda\")\n",
    "# model = BitnetForCausalLM(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980109cf-0bc4-45ba-a3be-c663f38973e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitnetForCausalLM(\n",
       "  (model): BitnetModel(\n",
       "    (embed_tokens): Embedding(32022, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x BitnetDecoderLayer(\n",
       "        (self_attn): BitnetAttention(\n",
       "          (q_proj): BitLinear(\n",
       "            in_features=512, out_features=512, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (k_proj): BitLinear(\n",
       "            in_features=512, out_features=512, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (v_proj): BitLinear(\n",
       "            in_features=512, out_features=512, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (o_proj): BitLinear(\n",
       "            in_features=512, out_features=512, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (rotary_emb): BitnetRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): BitnetMLP(\n",
       "          (gate_proj): BitLinear(\n",
       "            in_features=512, out_features=768, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (up_proj): BitLinear(\n",
       "            in_features=512, out_features=768, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (down_proj): BitLinear(\n",
       "            in_features=768, out_features=512, bias=False\n",
       "            (norm): RMSNorm()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32022, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "128345eb-d23f-4b5e-a169-3a7ebe519d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32256, 2048)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85a3867-b088-4f12-a461-2bfaf369877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f1b8cf4-7053-4cf0-a488-638031138611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToSmallEmb(nn.Module):\n",
    "    def __init__(self, emb, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim, bias=False)\n",
    "        self.emb = emb\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x)\n",
    "        # print(self.emb(x))\n",
    "        with torch.no_grad():\n",
    "            emb = self.emb(x)\n",
    "        return self.linear(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb55dfc-22a6-4836-9220-4dff2b466583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBigCodeForCausalLM(\n",
       "  (transformer): GPTBigCodeModel(\n",
       "    (wte): Embedding(49152, 768)\n",
       "    (wpe): Embedding(8192, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-19): 20 x GPTBigCodeBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTBigCodeAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=896, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTBigCodeMLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): PytorchGELUTanh()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ef6ec6-1b6e-4e84-b270-656ad9b1bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_small = ToSmallEmb(parent_model.model.embed_tokens, 2048, 512).to(\"cuda\").to(torch.float32)\n",
    "# to_small = ToSmallEmb(parent_model.model.embed_tokens, 2048, 512).to(\"cuda\")\n",
    "to_small = ToSmallEmb(parent_model.transformer.wte, 768, 384).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "868ba55e-20b1-4a67-b600-7a3bc6ef917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.embed_tokens = to_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6065df83-917d-4f15-9f9e-a30c1a0616de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc0c10ca-0da7-4816-9fb2-95bd8e775556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86471040"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a93774a-4d74-433f-86f3-c5a6ecd7906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bitnet size: 86.5M parameters\n"
     ]
    }
   ],
   "source": [
    "print(f\"bitnet size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74139731-62b2-4a7d-969a-35dc7700225f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/module.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model.__call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bdd4fbd-8f3e-4287-b29b-121fa1105045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e0272bf-5f54-4e31-a22b-bf99d0fc198d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7683863-3778-4893-90ce-960f052374b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ids = tokenizer([\"hello my friend, How are\", \"hi\"], return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d0e5882-4236-4a5a-bdd7-e342eb74e6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 7656,  1672, 11970,    30,  4971,   884],\n",
       "        [ 4980,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcc3ae70-2899-469b-8fd3-cda8d1b68527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 7656,  1672, 11970,    30,  4971,   884],\n",
       "        [ 4980,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e3ee34-c395-43e1-88c2-fa108b370dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_ids = inputs_ids['input_ids'].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91dabc53-5e32-4756-beeb-8c592e39ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_2 = parent_model(inputs_ids,  return_attentions_before_softmax=True, output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a88e1fb-c44f-439e-b246-2dffed0ba20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'attentions'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6bc2dee-0d8c-471a-9c75-93bbc2b5ce88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 6, 6])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2['attentions'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a860593d-c6b6-40cb-868f-43a93a338f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log = F.log_softmax(output_2['attentions'][0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65c31260-cf7b-4b5f-b077-05869da58bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.1131e-01, -2.2506e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.5084e-01, -2.1282e+00, -2.2749e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.6460e-01, -1.8871e+00, -1.4044e+00, -3.3703e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.3499e-01, -2.0290e+00, -2.0589e+00, -1.8960e+00, -2.7996e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.0791e+00, -1.8591e+00, -2.4366e+00, -2.0741e+00, -2.5895e+00,\n",
       "           -1.5319e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.4791e-01, -1.9842e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.1724e-01, -2.0915e+00, -2.6344e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.3942e-01, -2.5632e+00, -3.0188e+00, -1.2345e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-7.0089e-01, -1.8105e+00, -2.1740e+00, -1.6255e+00, -3.5149e+00,\n",
       "           -3.4028e+38],\n",
       "          [-7.6776e-01, -2.2240e+00, -2.2510e+00, -1.8024e+00, -3.5421e+00,\n",
       "           -2.0508e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.2392e-01, -1.2849e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.2764e-01, -1.5515e+00, -2.6966e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.8582e-01, -1.2648e+00, -2.0404e+00, -1.7410e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.2251e-01, -2.0444e+00, -3.0744e+00, -1.6350e+00, -3.3145e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.0138e+00, -1.8880e+00, -2.6095e+00, -1.5727e+00, -2.6369e+00,\n",
       "           -2.0161e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.6833e-02, -2.4869e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.2831e-01, -3.1037e+00, -2.5831e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.4367e-01, -1.9500e+00, -3.6602e+00, -1.6591e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.8180e-01, -2.2829e+00, -3.1115e+00, -1.5731e+00, -2.4398e+00,\n",
       "           -3.4028e+38],\n",
       "          [-6.7988e-01, -2.1927e+00, -3.4911e+00, -1.5863e+00, -3.4922e+00,\n",
       "           -2.1530e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.7194e-01, -1.4351e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.0447e-01, -1.8351e+00, -2.2742e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.0839e-01, -2.0439e+00, -1.9874e+00, -2.6779e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.0548e-01, -1.9642e+00, -2.1875e+00, -1.7561e+00, -3.5407e+00,\n",
       "           -3.4028e+38],\n",
       "          [-6.3129e-01, -2.2383e+00, -2.7372e+00, -1.6454e+00, -3.3635e+00,\n",
       "           -2.6715e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.6055e-01, -1.9083e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.1553e-01, -2.3517e+00, -2.3159e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-9.8752e-01, -3.9386e+00, -4.8410e+00, -5.1062e-01, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.6695e-01, -2.0118e+00, -2.2072e+00, -2.2004e+00, -2.5481e+00,\n",
       "           -3.4028e+38],\n",
       "          [-9.3193e-01, -2.2454e+00, -2.1845e+00, -2.0040e+00, -2.2038e+00,\n",
       "           -1.9476e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.3659e-01, -1.5574e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.7280e-01, -1.5708e+00, -2.2700e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-7.9687e-01, -2.0065e+00, -2.2971e+00, -1.1576e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-9.3735e-01, -1.6189e+00, -1.5855e+00, -1.6796e+00, -3.9674e+00,\n",
       "           -3.4028e+38],\n",
       "          [-7.6667e-01, -2.0248e+00, -1.7649e+00, -1.7786e+00, -3.8746e+00,\n",
       "           -3.1562e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.8635e-01, -1.7719e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.8215e-01, -2.3487e+00, -2.6447e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.2959e-01, -2.8006e+00, -2.9999e+00, -1.4327e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.1413e-01, -2.6138e+00, -3.3354e+00, -1.5488e+00, -4.0332e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.0996e+00, -1.9384e+00, -2.8084e+00, -1.5123e+00, -3.8263e+00,\n",
       "           -1.5114e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.5782e-01, -1.9242e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.5716e-01, -2.0833e+00, -1.7383e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.5227e-01, -1.4801e+00, -1.5301e+00, -3.3519e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.9645e-01, -2.1467e+00, -2.7487e+00, -1.7755e+00, -3.1935e+00,\n",
       "           -3.4028e+38],\n",
       "          [-6.1290e-01, -1.9754e+00, -2.8120e+00, -1.6879e+00, -3.3704e+00,\n",
       "           -3.2154e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.8586e-01, -9.5495e-01, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.1001e-01, -1.5919e+00, -2.7642e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.1697e-01, -1.5961e+00, -2.4274e+00, -1.3195e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.9477e-01, -1.8220e+00, -2.7991e+00, -2.0412e+00, -3.2742e+00,\n",
       "           -3.4028e+38],\n",
       "          [-7.0295e-01, -2.0025e+00, -3.3682e+00, -1.9661e+00, -3.4992e+00,\n",
       "           -1.8006e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.4740e-01, -1.9874e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.9064e-01, -2.0012e+00, -2.1452e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.1048e-01, -1.7493e+00, -2.3104e+00, -2.0661e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.1457e-01, -1.7895e+00, -2.5327e+00, -1.7765e+00, -3.1368e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.0690e+00, -1.8911e+00, -2.3958e+00, -1.8762e+00, -2.8176e+00,\n",
       "           -1.6009e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.8870e-01, -1.1330e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.3871e-01, -1.7176e+00, -3.4155e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.7378e-01, -1.7195e+00, -2.6088e+00, -1.1091e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.8474e-01, -1.7818e+00, -2.9076e+00, -1.5833e+00, -2.6949e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.3393e+00, -1.6765e+00, -3.1632e+00, -1.4977e+00, -3.2027e+00,\n",
       "           -1.4091e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.0345e-01, -1.6923e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.2246e-01, -1.8949e+00, -2.0771e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.7230e-01, -2.0248e+00, -2.2068e+00, -2.0072e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.6633e-01, -2.1568e+00, -2.3363e+00, -2.1334e+00, -2.2870e+00,\n",
       "           -3.4028e+38],\n",
       "          [-6.8650e-01, -2.2557e+00, -2.4290e+00, -2.2277e+00, -2.3757e+00,\n",
       "           -2.2728e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.0444e-02, -2.5601e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.6923e-01, -2.4608e+00, -2.6546e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.4972e-01, -2.4888e+00, -2.6767e+00, -2.6710e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.0204e-01, -2.5636e+00, -2.7560e+00, -2.7466e+00, -2.8829e+00,\n",
       "           -3.4028e+38],\n",
       "          [-3.7778e-01, -2.5784e+00, -2.7704e+00, -2.7601e+00, -2.8921e+00,\n",
       "           -2.8588e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.5725e-01, -7.3038e-01, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.1529e-01, -1.2438e+00, -1.3123e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.0566e+00, -1.4749e+00, -1.5358e+00, -1.5688e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.2414e+00, -1.6630e+00, -1.7229e+00, -1.7585e+00, -1.7686e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.4058e+00, -1.8223e+00, -1.8802e+00, -1.9210e+00, -1.9273e+00,\n",
       "           -1.9062e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.6948e-01, -1.8586e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.3884e-01, -1.5276e+00, -1.6119e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.3039e-01, -1.6708e+00, -1.7233e+00, -1.6218e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.0616e+00, -1.8163e+00, -1.8543e+00, -1.7564e+00, -1.8186e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.2374e+00, -1.9821e+00, -2.0142e+00, -1.9105e+00, -1.9718e+00,\n",
       "           -1.8875e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.4788e-01, -7.4057e-01, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.0317e+00, -9.9821e-01, -1.2907e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.2402e+00, -1.2425e+00, -1.5365e+00, -1.5756e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.4272e+00, -1.4340e+00, -1.7278e+00, -1.7702e+00, -1.7505e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.5555e+00, -1.5980e+00, -1.8959e+00, -1.9440e+00, -1.9220e+00,\n",
       "           -1.9175e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.1571e-01, -1.6397e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.2440e-01, -1.6929e+00, -1.8211e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.3852e-01, -1.8818e+00, -2.0246e+00, -2.0248e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.7640e-01, -1.9674e+00, -2.0969e+00, -2.0944e+00, -2.2467e+00,\n",
       "           -3.4028e+38],\n",
       "          [-7.8346e-01, -2.0640e+00, -2.1915e+00, -2.1917e+00, -2.3391e+00,\n",
       "           -2.3399e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.8937e-01, -1.7573e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.3845e-01, -1.6448e+00, -1.8207e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-5.9351e-01, -1.8117e+00, -2.0064e+00, -1.8987e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-7.5199e-01, -1.9552e+00, -2.1425e+00, -2.0255e+00, -1.9823e+00,\n",
       "           -3.4028e+38],\n",
       "          [-8.7489e-01, -2.0902e+00, -2.2850e+00, -2.1736e+00, -2.1291e+00,\n",
       "           -2.0800e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.1571e-01, -2.2140e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.6567e-01, -2.4473e+00, -2.7159e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.3099e-01, -2.5441e+00, -2.8098e+00, -2.6957e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.8379e-01, -2.5996e+00, -2.8730e+00, -2.7559e+00, -2.9433e+00,\n",
       "           -3.4028e+38],\n",
       "          [-3.3741e-01, -2.6600e+00, -2.9259e+00, -2.8139e+00, -2.9961e+00,\n",
       "           -2.9401e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.1385e+00, -1.2538e-01, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.4532e+00, -9.5561e-01, -5.3823e-01, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.9256e+00, -1.4391e+00, -1.0388e+00, -9.4354e-01, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.2629e+00, -1.7830e+00, -1.3682e+00, -1.2730e+00, -1.2616e+00,\n",
       "           -3.4028e+38],\n",
       "          [-4.4830e+00, -2.0283e+00, -1.6243e+00, -1.5265e+00, -1.5150e+00,\n",
       "           -1.5006e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-7.1235e-01, -6.7430e-01, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-8.8507e-01, -1.0263e+00, -1.4741e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.1763e+00, -1.1789e+00, -1.5936e+00, -1.7105e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-1.3596e+00, -1.3466e+00, -1.7619e+00, -1.8785e+00, -1.8414e+00,\n",
       "           -3.4028e+38],\n",
       "          [-1.5220e+00, -1.4817e+00, -1.8918e+00, -2.0116e+00, -1.9686e+00,\n",
       "           -2.0384e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.2235e-01, -1.6126e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-4.6133e-01, -1.5877e+00, -1.8009e+00, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-6.4676e-01, -1.6918e+00, -1.8976e+00, -1.9509e+00, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-7.7116e-01, -1.8257e+00, -2.0242e+00, -2.0811e+00, -2.1242e+00,\n",
       "           -3.4028e+38],\n",
       "          [-9.1982e-01, -1.9200e+00, -2.1112e+00, -2.1701e+00, -2.2125e+00,\n",
       "           -2.2061e+00]],\n",
       "\n",
       "         [[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-2.9019e+00, -5.6484e-02, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.1330e+00, -8.7891e-01, -6.1401e-01, -3.4028e+38, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.4254e+00, -1.3403e+00, -1.0888e+00, -9.9674e-01, -3.4028e+38,\n",
       "           -3.4028e+38],\n",
       "          [-3.7388e+00, -1.6418e+00, -1.4040e+00, -1.3121e+00, -1.3178e+00,\n",
       "           -3.4028e+38],\n",
       "          [-3.9396e+00, -1.8899e+00, -1.6530e+00, -1.5630e+00, -1.5686e+00,\n",
       "           -1.5134e+00]]]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "981674b2-7c50-4282-9c55-fd5e16e177ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_log_real = F.log_softmax(output['attentions'][0][1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94582694-4ad9-45c1-9fa5-258e5b2d995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = F.softmax(output['attentions'][0][1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ef43988-7cd3-4a1d-a2a8-4e04815db759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3213, -0.2210], device='cuda:0', grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p * (p_log - p_log_real)).sum(axis=-1).mean(axis=(-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "966be439-315f-4b67-86ca-d095f08f5b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_2['attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e591710c-2524-421b-b620-cb56e064c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.log_softmax(output_2['attentions'][0][:, 1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2bb4a-2c57-446a-b934-f95046825d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2749cbae-3696-4c8b-901e-3ce315e8c4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06b7af91-4c08-4b17-a601-3043dec273be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model(inputs_ids['input_ids'].to(\"cuda\"), output_attentions=True)\n",
    "output = model(inputs_ids, output_attentions=True, return_attentions_before_softmax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cfeea-3fe1-4eed-a9ac-cf04c32e60c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b8d873-0ca0-4f00-bee9-8238a243024c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 32022])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4202d930-fba4-414f-9393-87313ac3ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.nn.functional.softmax(output.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67ba9dd7-e5eb-49b3-9ad9-8fad63e0392b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493eb78e-978b-47e7-92ca-ebb9b4a6b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_2 = model_2(inputs_ids,  output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "607023a1-0401-443c-b3d3-4f7ad4f8fd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values', 'attentions'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c421bca-3de4-4094-be68-cf40188260c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac0f3bf1-1fe2-4ade-b011-74f8ccd8b5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4901, 0.5099, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3610, 0.3349, 0.3041, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2849, 0.2415, 0.2467, 0.2269, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1930, 0.1915, 0.1871, 0.2247, 0.2038, 0.0000, 0.0000],\n",
       "        [0.1806, 0.1618, 0.1765, 0.1523, 0.1649, 0.1640, 0.0000],\n",
       "        [0.1463, 0.1421, 0.1339, 0.1563, 0.1445, 0.1388, 0.1381]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['attentions'][0][0][0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e8beaaf-3357-4252-935e-a90bfe70101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = F.log_softmax(output['attentions'][0][0, 1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c835aefe-e85f-4284-9e25-9f75579a6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_p = F.softmax(output['attentions'][0][0, 1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20293c76-9388-407a-a311-9f7701d8c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5367, 0.4633, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3252, 0.3354, 0.3395, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2541, 0.2816, 0.2119, 0.2524, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1889, 0.2360, 0.2040, 0.1908, 0.1804, 0.0000, 0.0000],\n",
       "        [0.1747, 0.1630, 0.1596, 0.1760, 0.1813, 0.1455, 0.0000],\n",
       "        [0.1313, 0.1751, 0.1311, 0.1388, 0.1336, 0.1461, 0.1440]],\n",
       "       device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d36649ed-927d-4436-a625-5cdeff48cee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "         -3.4028e+38, -3.4028e+38],\n",
       "        [-1.6772e-01, -1.8682e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
       "         -3.4028e+38, -3.4028e+38],\n",
       "        [-3.9324e-01, -1.8360e+00, -1.7978e+00, -3.4028e+38, -3.4028e+38,\n",
       "         -3.4028e+38, -3.4028e+38],\n",
       "        [-8.2617e-01, -1.4385e+00, -1.6120e+00, -2.0754e+00, -3.4028e+38,\n",
       "         -3.4028e+38, -3.4028e+38],\n",
       "        [-5.2994e-01, -2.4086e+00, -2.4951e+00, -2.8222e+00, -1.7178e+00,\n",
       "         -3.4028e+38, -3.4028e+38],\n",
       "        [-1.1486e+00, -1.9705e+00, -1.7919e+00, -2.5842e+00, -1.7926e+00,\n",
       "         -2.0031e+00, -3.4028e+38],\n",
       "        [-1.6035e+00, -2.3019e+00, -1.6617e+00, -2.8207e+00, -1.7024e+00,\n",
       "         -1.7932e+00, -2.2958e+00]], device='cuda:0',\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cd35ed01-b1a8-48ef-be28-fbd1febe8f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3252, 0.3354, 0.3395], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_p[2, :2 + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d5a9794-d6b0-4c8a-a011-e1ccc45cb22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([ 0.2440, -0.5091], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([ 0.2374, -0.2493, -0.2435], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "tensor([ 0.1382, -0.0482, -0.0128, -0.1764], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([ 0.2147, -0.2276, -0.1847, -0.2223, -0.0009], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([ 0.1041, -0.0255,  0.0069, -0.1491, -0.0154, -0.0110], device='cuda:0',\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([ 0.0560, -0.0980,  0.0485, -0.1174,  0.0415,  0.0190, -0.0515],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "l = 0 \n",
    "for i in range(len(a)):\n",
    "    print((a_p[i, :i + 1] * (b[i, :i + 1] - a[i, :i + 1])))\n",
    "    l -= (a_p[i, :i + 1] * (b[i, :i + 1] - a[i, :i + 1])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe735cac-d667-4768-89a1-cdd8c0f24f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab0c5604-516b-4619-b808-76c623677083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2323, device='cuda:0', grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a596ed2e-0dbb-4acd-a759-98929f26bc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 7, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6da746-f404-4ce3-ab56-56aff38ebb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16, 7, 7]), torch.Size([1, 16, 7, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.attentions[0].shape, output_2.attentions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c88a2ac-666a-4c74-8b31-1d0ea4b9484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones(1, 16, 7, 7).triu(diagonal=1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0dd53f0-20b9-49d5-a4f0-43455f914052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.7229, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(output.attentions[0] * torch.log((output_2.attentions[0] + mask) / (output.attentions[0] + mask))).sum(axis=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4494cd9-1bad-45bb-90a1-2f04450a5862",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = output.attentions[0][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "025c2060-58e1-42d5-8c81-710e7e6c635e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = output_2.attentions[0][0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a947ff6-1880-4984-bf62-1393876ce20a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    nan,     nan,     nan,     nan,     nan,     nan, -0.6093],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q * torch.log((p) / q)).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23f47e6-3cc6-481f-b16f-b082fed3361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2242, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q * torch.log((p + upper_tri) / (q + upper_tri))).sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17f72990-dbb7-454c-9859-15dfcad87d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "upper_tri = torch.ones(7, 7).triu()  - torch.eye(7, 7)\n",
    "upper_tri = upper_tri.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7b60bd9-587a-4f43-945b-0f9d9317630c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eye() received an invalid combination of arguments - got (int, int, int, int), but expected one of:\n * (int n, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int n, int m, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m upper_tri \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m)\u001b[38;5;241m.\u001b[39mtriu()  \u001b[38;5;241m-\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m upper_tri \u001b[38;5;241m=\u001b[39m upper_tri\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: eye() received an invalid combination of arguments - got (int, int, int, int), but expected one of:\n * (int n, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (int n, int m, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "upper_tri = torch.ones(1, 16, 7, 7).triu()  - torch.eye(1, 16, 7, 7)\n",
    "upper_tri = upper_tri.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62440590-d890-4221-bde1-cf5b4109f1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 1., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 1., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 1., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 1., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1, 16, 7, 7).triu(diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f41e5ef-3b2d-4d5e-9f71-ffd204c8421a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
